"""
Auto-generated from notebooks/model_extraction_attacks.ipynb.

Generated by tools/convert_notebooks.py. Do not edit manually.
"""


def main():

    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.utils.data import DataLoader
    from tqdm import tqdm, trange
    import matplotlib.pyplot as plt


    import torchvision
    from torchvision import transforms, datasets, models
    from torchvision.models import ResNet18_Weights, ResNet34_Weights  # Import weights enums


    # Define device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


    # TODO: Load CIFAR-100 dataset

    # Define transforms for training and testing
    transform_train = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5071, 0.4865, 0.4409],
                             std=[0.2673, 0.2564, 0.2762]),
    ])

    transform_test = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5071, 0.4865, 0.4409],
                             std=[0.2673, 0.2564, 0.2762]),
    ])

    # Load the training and test sets
    train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)
    test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)

    # Define data loaders
    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)
    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)


    # TODO: Load pretrained ResNet-34 model

    # Load the pre-trained ResNet-34 model
    # resnet34 = models.resnet34(pretrained=True)
    resnet34 = models.resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)

    # Modify the final fully connected layer to match CIFAR100 classes
    num_ftrs = resnet34.fc.in_features
    resnet34.fc = nn.Linear(num_ftrs, 100)

    # Move the model to the appropriate device
    resnet34 = resnet34.to(device)


    # TODO: Train the model on CIFAR100

    # Define loss function and optimizer
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(resnet34.parameters(), lr=0.001)

    # Number of epochs
    epochs = 10

    # Training loop
    for epoch in range(epochs):
        resnet34.train()  # Set model to training mode
        running_loss = 0.0

        # Use tqdm to wrap the DataLoader for a progress bar
        for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}'):
            inputs, labels = inputs.to(device), labels.to(device)  # Move data to device

            optimizer.zero_grad()  # Zero the parameter gradients

            outputs = resnet34(inputs)  # Forward pass
            loss = criterion(outputs, labels)  # Compute loss
            loss.backward()  # Backward pass
            optimizer.step()  # Optimize

            running_loss += loss.item()  # Accumulate loss

        avg_loss = running_loss / len(train_loader)  # Average loss for the epoch
        print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}')

        # Validation phase
        resnet34.eval()  # Set model to evaluation mode
        correct = 0
        total = 0

        with torch.no_grad():  # Disable gradient computation
            for inputs, labels in test_loader:
                inputs, labels = inputs.to(device), labels.to(device)  # Move data to device
                outputs = resnet34(inputs)  # Forward pass
                _, predicted = torch.max(outputs.data, 1)  # Get predictions
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        accuracy = 100 * correct / total  # Compute accuracy
        print(f'Validation Accuracy: {accuracy:.2f}%')

    # Save the trained model
    torch.save(resnet34.state_dict(), 'resnet34_cifar100.pth')
    print("Model saved as resnet34_cifar100.pth")


    torch.save(resnet34.state_dict(), 'resnet34_cifar100.pth')
    print("Model saved as resnet34_cifar100.pth")


    def knowledge_distillation(victim_model, attacker_model, loader, optimizer, epochs, T):
        """
        Perform knowledge distillation from victim_model to attacker_model.

        Parameters:
        - victim_model: The pre-trained teacher model.
        - attacker_model: The student model to be trained.
        - loader: DataLoader for training data.
        - optimizer: Optimizer for the student model.
        - epochs: Number of training epochs.
        - T: Temperature parameter.
        """
        victim_model.eval()      # Set teacher to evaluation mode
        attacker_model.train()  # Set student to training mode

        criterion = nn.KLDivLoss(reduction='batchmean')
        softmax = nn.Softmax(dim=1)
        log_softmax = nn.LogSoftmax(dim=1)

        for epoch in range(epochs):
            running_loss = 0.0

            # Use tqdm to wrap the DataLoader for a progress bar
            for inputs, _ in tqdm(loader, desc=f'Distillation Epoch {epoch+1}/{epochs}'):
                inputs = inputs.to(device)

                with torch.no_grad():
                    teacher_logits = victim_model(inputs)
                    teacher_probs = softmax(teacher_logits / T)

                student_logits = attacker_model(inputs)
                student_log_probs = log_softmax(student_logits / T)

                loss = criterion(student_log_probs, teacher_probs)

                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

                running_loss += loss.item()

            avg_loss = running_loss / len(loader)
            print(f'Distillation Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}')


    # TODO: Load or implement attacks

    import torch.nn.functional as F

    def fgsm_attack(model, loss_fn, images, labels, epsilon):
        images = images.clone().detach().to(device)
        labels = labels.clone().detach().to(device)

        images.requires_grad = True
        outputs = model(images)
        loss = loss_fn(outputs, labels)
        model.zero_grad()
        loss.backward()
        data_grad = images.grad.data

        perturbed_images = images + epsilon * data_grad.sign()
        perturbed_images = torch.clamp(perturbed_images, 0, 1)

        return perturbed_images

    def pgd_attack(model, loss_fn, images, labels, epsilon, alpha, iters):
        ori_images = images.clone().detach().to(device)
        images = images.clone().detach().to(device)

        for i in range(iters):
            images.requires_grad = True
            outputs = model(images)
            loss = loss_fn(outputs, labels)
            model.zero_grad()
            loss.backward()
            data_grad = images.grad.data

            images = images + alpha * data_grad.sign()
            eta = torch.clamp(images - ori_images, min=-epsilon, max=epsilon)
            images = torch.clamp(ori_images + eta, 0, 1).detach()

        return images


    # TODO: Fill in the transferability_attack function

    def transferability_attack(model, victim, loader, attack, epsilon=0.03, alpha=0.007, iters=10):
        """
        Perform adversarial attack using the attacker model and evaluate on the victim model.

        Parameters:
        - model: The attacker model used to generate adversarial examples.
        - victim: The victim model to be evaluated on adversarial examples.
        - loader: DataLoader for the dataset to attack.
        - attack: The attack method ('fgsm' or 'pgd').
        - epsilon: Perturbation magnitude.
        - alpha: Step size for PGD.
        - iters: Number of iterations for PGD.

        Returns:
        - Accuracy of the victim model on adversarial examples.
        """
        victim.eval()
        model.eval()
        correct = 0
        total = 0
        loss_fn = nn.CrossEntropyLoss()

        for inputs, labels in loader:
            inputs, labels = inputs.to(device), labels.to(device)

            if attack == 'fgsm':
                adv_images = fgsm_attack(model, loss_fn, inputs, labels, epsilon)
            elif attack == 'pgd':
                adv_images = pgd_attack(model, loss_fn, inputs, labels, epsilon, alpha, iters)
            else:
                raise ValueError("Unsupported attack type")

            outputs = victim(adv_images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        accuracy = 100 * correct / total
        print(f'Victim Model Accuracy on {attack.upper()} Adversarial Examples: {accuracy:.2f}%')
        return accuracy


    # TODO: Load CIFAR-10 dataset

    # Define transforms for CIFAR-10
    transform_cifar10 = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5071, 0.4865, 0.4409],
                             std=[0.2673, 0.2564, 0.2762]),
    ])

    # Load CIFAR-10 training and test sets
    cifar10_train = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_cifar10)
    cifar10_test = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_cifar10)

    # Define data loaders
    cifar10_train_loader = DataLoader(cifar10_train, batch_size=64, shuffle=True, num_workers=4)
    cifar10_test_loader = DataLoader(cifar10_test, batch_size=64, shuffle=False, num_workers=4)


    # TODO: Check if classes are present in both datasets

    # Get class names
    cifar10_classes = cifar10_train.classes
    cifar100_classes = train_dataset.classes

    # Check for overlap
    overlapping_classes = set(cifar10_classes).intersection(set(cifar100_classes))
    print("Overlapping Classes between CIFAR-10 and CIFAR-100:")
    print(overlapping_classes)


    # TODO: Load pretrained ResNet-18 model

    # Load the pre-trained ResNet-18 model
    resnet18_teacher = models.resnet18(pretrained=True)

    # Modify the final fully connected layer to match CIFAR100 classes
    num_ftrs = resnet18_teacher.fc.in_features
    resnet18_teacher.fc = nn.Linear(num_ftrs, 100)

    # Load the trained weights if available
    # resnet18_teacher.load_state_dict(torch.load('resnet18_cifar100.pth'))

    resnet18_teacher = resnet18_teacher.to(device)
    resnet18_teacher.eval()

    # TODO: Extract the model

    # Define the student model (attacker)
    resnet18_student = models.resnet18(pretrained=False)
    resnet18_student.fc = nn.Linear(num_ftrs, 100)
    resnet18_student = resnet18_student.to(device)

    # Define optimizer for the student model
    optimizer_student = optim.Adam(resnet18_student.parameters(), lr=0.001)

    # Perform knowledge distillation
    epochs_distill = 10
    temperature = 4

    knowledge_distillation(resnet18_teacher, resnet18_student, train_loader, optimizer_student, epochs_distill, temperature)

    # Save the student model
    torch.save(resnet18_student.state_dict(), 'resnet18_student_cifar100.pth')
    print("Student model saved as resnet18_student_cifar100.pth")


    # TODO: Report accuracy on CIFAR100

    def evaluate_model(model, loader):
        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for inputs, labels in loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        accuracy = 100 * correct / total
        return accuracy

    student_accuracy = evaluate_model(resnet18_student, test_loader)
    print(f'Extracted Student Model Accuracy on CIFAR100 Test Set: {student_accuracy:.2f}%')


    # TODO: Load ResNet-18 model

    # Load the ResNet-18 model without pre-training
    resnet18_no_pretrain = models.resnet18(pretrained=False)

    # Modify the final fully connected layer to match CIFAR100 classes
    num_ftrs = resnet18_no_pretrain.fc.in_features
    resnet18_no_pretrain.fc = nn.Linear(num_ftrs, 100)

    resnet18_no_pretrain = resnet18_no_pretrain.to(device)


    # TODO: Extract the model

    # Define the student model (attacker)
    resnet18_student_no_pretrain = models.resnet18(pretrained=False)
    resnet18_student_no_pretrain.fc = nn.Linear(num_ftrs, 100)
    resnet18_student_no_pretrain = resnet18_student_no_pretrain.to(device)

    # Define optimizer for the student model
    optimizer_student_no_pretrain = optim.Adam(resnet18_student_no_pretrain.parameters(), lr=0.001)

    # Perform knowledge distillation
    epochs_distill_no_pretrain = 10
    temperature = 4

    knowledge_distillation(resnet18_teacher, resnet18_student_no_pretrain, train_loader, optimizer_student_no_pretrain, epochs_distill_no_pretrain, temperature)

    # Save the student model
    torch.save(resnet18_student_no_pretrain.state_dict(), 'resnet18_student_no_pretrain_cifar100.pth')
    print("Student model without pre-training saved as resnet18_student_no_pretrain_cifar100.pth")


    # TODO: Load pretrained ResNet-18 model

    # Load the pre-trained ResNet-18 model
    resnet18_full_teacher = models.resnet18(pretrained=True)

    # Modify the final fully connected layer to match CIFAR100 classes
    num_ftrs = resnet18_full_teacher.fc.in_features
    resnet18_full_teacher.fc = nn.Linear(num_ftrs, 100)

    resnet18_full_teacher = resnet18_full_teacher.to(device)
    resnet18_full_teacher.eval()

    # TODO: Extract the model

    # Define the student model (attacker)
    resnet18_full_student = models.resnet18(pretrained=False)
    resnet18_full_student.fc = nn.Linear(num_ftrs, 100)
    resnet18_full_student = resnet18_full_student.to(device)

    # Define optimizer for the student model
    optimizer_full_student = optim.Adam(resnet18_full_student.parameters(), lr=0.001)

    # Perform knowledge distillation using the entire CIFAR10 dataset
    knowledge_distillation(resnet18_full_teacher, resnet18_full_student, cifar10_train_loader, optimizer_full_student, epochs_distill, temperature)

    # Save the student model
    torch.save(resnet18_full_student.state_dict(), 'resnet18_full_student_cifar100.pth')
    print("Student model using full CIFAR10 dataset saved as resnet18_full_student_cifar100.pth")


    # TODO: Report accuracy on CIFAR100

    full_student_accuracy = evaluate_model(resnet18_full_student, test_loader)
    print(f'Extracted Student Model using Full CIFAR10 Dataset Accuracy on CIFAR100 Test Set: {full_student_accuracy:.2f}%')


    # TODO: Load pretrained ResNet-18 model

    # Load the pre-trained ResNet-18 model
    resnet18_cifar100_teacher = models.resnet18(pretrained=True)

    # Modify the final fully connected layer to match CIFAR100 classes
    num_ftrs = resnet18_cifar100_teacher.fc.in_features
    resnet18_cifar100_teacher.fc = nn.Linear(num_ftrs, 100)

    # Load the trained weights if available
    # resnet18_cifar100_teacher.load_state_dict(torch.load('resnet18_cifar100.pth'))

    resnet18_cifar100_teacher = resnet18_cifar100_teacher.to(device)
    resnet18_cifar100_teacher.eval()

    # TODO: Extract the model

    # Define the student model (attacker)
    resnet18_cifar100_student = models.resnet18(pretrained=False)
    resnet18_cifar100_student.fc = nn.Linear(num_ftrs, 100)
    resnet18_cifar100_student = resnet18_cifar100_student.to(device)

    # Define optimizer for the student model
    optimizer_cifar100_student = optim.Adam(resnet18_cifar100_student.parameters(), lr=0.001)

    # Perform knowledge distillation using CIFAR100 training dataset
    epochs_distill_cifar100 = 10
    temperature = 4

    knowledge_distillation(resnet18_cifar100_teacher, resnet18_cifar100_student, train_loader, optimizer_cifar100_student, epochs_distill_cifar100, temperature)

    # Save the student model
    torch.save(resnet18_cifar100_student.state_dict(), 'resnet18_cifar100_student_cifar100.pth')
    print("Student model using CIFAR100 training dataset saved as resnet18_cifar100_student_cifar100.pth")


    # TODO: Report accuracy on CIFAR100

    cifar100_student_accuracy = evaluate_model(resnet18_cifar100_student, test_loader)
    print(f'Extracted Student Model using CIFAR100 Training Dataset Accuracy on CIFAR100 Test Set: {cifar100_student_accuracy:.2f}%')


if __name__ == "__main__":
    main()
