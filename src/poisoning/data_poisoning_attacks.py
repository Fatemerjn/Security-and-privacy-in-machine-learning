"""
Auto-generated from notebooks/data_poisoning_attacks.ipynb.

Generated by tools/convert_notebooks.py. Do not edit manually.
"""


def main():
    std_id = '402203389'

    import numpy as np
    from tqdm import trange, tqdm
    from sklearn.manifold import TSNE
    from matplotlib import pyplot as plt

    import torch
    from torch import nn
    from torch.optim import Adam
    import torch.nn.functional as F
    from torch.nn import CrossEntropyLoss
    from torch.utils.data import DataLoader, TensorDataset, ConcatDataset

    from torchvision import transforms
    from torchvision.datasets import CIFAR10
    from torchvision.models import resnet18, ResNet18_Weights

    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    device


    class TensorCIFAR10(CIFAR10):
        def __getitem__(self, index):
            img, target = super().__getitem__(index)
            target = torch.tensor(target)
            return img, target


    transform_train = transforms.Compose([
        transforms.RandomCrop(32, padding=4),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
    ])

    transform_test = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
    ])

    batch_size = 128

    trainset = TensorCIFAR10(root='./data', train=True, download=True, transform=transform_train)
    testset = TensorCIFAR10(root='./data', train=False, download=True, transform=transform_test)


    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)
    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)

    print(f'The trainloader consists of {len(trainloader.dataset)} samples.')
    print(f'The testloader consists of {len(testloader.dataset)} samples.')


    class ResNet18(nn.Module):
        def __init__(self):
            super(ResNet18, self).__init__()
            self.feature_extractor = nn.Sequential(
                *list(resnet18(weights=ResNet18_Weights.DEFAULT).children())[:-2]
            )
            self.fc = nn.Linear(512, 10)

        def get_features(self, x):
            features = self.feature_extractor(x)
            return torch.flatten(features, start_dim=1)

        def forward(self, x):
            features = self.feature_extractor(x)
            features = torch.flatten(features, start_dim=1)
            logits = self.fc(features)
            return logits


    clean_model = ResNet18().to(device)
    for param in clean_model.feature_extractor.parameters():
        param.requires_grad = False


    def train_model(model, loader, optimizer, criterion, n_epochs=15):
        model.train()
        for epoch in range(n_epochs):
            running_loss = 0.0
            correct = 0
            total = 0
            for inputs, targets in loader:
                inputs, targets = inputs.to(device), targets.to(device)
                optimizer.zero_grad()
                outputs = model(inputs)
                loss = criterion(outputs, targets)
                loss.backward()
                optimizer.step()

                running_loss += loss.item() * inputs.size(0)
                _, predicted = outputs.max(1)
                total += targets.size(0)
                correct += predicted.eq(targets).sum().item()
            acc = 100. * correct / total
            epoch_loss = running_loss / total
            print(f'Epoch [{epoch+1}/{n_epochs}] Loss: {epoch_loss:.4f} Acc: {acc:.2f}%')


    criterion = CrossEntropyLoss()
    optimizer = Adam(clean_model.fc.parameters(), lr=1e-3)

    train_model(clean_model, trainloader, optimizer, criterion, n_epochs=15)

    torch.save(clean_model.state_dict(), 'clean_model.pth')


    def test_model(model, loader):
        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for inputs, targets in loader:
                inputs, targets = inputs.to(device), targets.to(device)
                outputs = model(inputs)
                _, predicted = outputs.max(1)
                total += targets.size(0)
                correct += predicted.eq(targets).sum().item()
        return 100. * correct / total


    acc = test_model(clean_model, testloader)
    print(f'Clean accuracy on the clean model is {acc:.2f}%')


    def poisoning_example_generation(model, t, b, lr, beta=0.25, max_iters=1000):
        model.eval()

        x = b.clone().to(device)
        t = t.clone().to(device)
        b = b.clone().to(device)

        x.requires_grad = True
        optimizer = torch.optim.SGD([x], lr=lr)

        with torch.no_grad():
            f_t = model.get_features(t.unsqueeze(0))

        for i in range(max_iters):
            optimizer.zero_grad()
            f_x = model.get_features(x.unsqueeze(0))
            L_p = ((f_x - f_t)**2).sum()
            L_p.backward()

            with torch.no_grad():
                x_hat = x - lr * x.grad
                x = (x_hat + lr * beta * b) / (1 + beta * lr)
                x.requires_grad = True

        return x.detach().cpu()


    base_idx = int(std_id) % 846
    base_image, base_label = testloader.dataset[base_idx]
    plt.imshow(np.transpose((base_image * torch.tensor((0.2023, 0.1994, 0.2010)).view(3,1,1) + torch.tensor((0.4914, 0.4822, 0.4465)).view(3,1,1)).numpy(), (1,2,0)))
    plt.title(f'Base Image (Label: {base_label})')
    plt.show()


    clean_model.eval()
    with torch.no_grad():
        inp = base_image.unsqueeze(0).to(device)
        out = clean_model(inp)
        pred = out.argmax(dim=1).item()
        print('Model logits:', out)
        print('Model prediction:', pred)
        if pred != base_label:
            print('Base image is misclassified. Consider choosing another index if needed.')


    target_idx = (base_idx + 50) % len(testloader.dataset)
    target_image, target_label = testloader.dataset[target_idx]
    plt.imshow(np.transpose((target_image * torch.tensor((0.2023, 0.1994, 0.2010)).view(3,1,1) + torch.tensor((0.4914, 0.4822, 0.4465)).view(3,1,1)).numpy(), (1,2,0)))
    plt.title(f'Target Image (Label: {target_label})')
    plt.show()

    with torch.no_grad():
        inp = target_image.unsqueeze(0).to(device)
        out = clean_model(inp)
        pred_target = out.argmax(dim=1).item()
        print('Model logits for target:', out)
        print('Model prediction for target:', pred_target)


    poison = poisoning_example_generation(clean_model, t=target_image, b=base_image, lr=0.1, beta=0.25, max_iters=200)
    plt.imshow(np.transpose((poison * torch.tensor((0.2023, 0.1994, 0.2010)).view(3,1,1) + torch.tensor((0.4914, 0.4822, 0.4465)).view(3,1,1)).numpy(), (1,2,0)))
    plt.title('Poisoned Image')
    plt.show()

    with torch.no_grad():
        inp = poison.unsqueeze(0).to(device)
        out = clean_model(inp)
        pred_poison = out.argmax(dim=1).item()
        print('Model logits for poison:', out)
        print('Model prediction for poison:', pred_poison)


    poison_label = target_label
    poison_dataset = TensorDataset(poison.unsqueeze(0), torch.tensor([poison_label]))
    poisoned_dataset = ConcatDataset([trainset, poison_dataset])
    poisoned_loader = DataLoader(poisoned_dataset, batch_size=batch_size, shuffle=True, num_workers=2)

    print(f'The trainloader consists of {len(trainloader.dataset)} samples.')
    print(f'The poisoned trainloader consists of {len(poisoned_loader.dataset)} samples.')


    attacked_model = ResNet18().to(device)
    attacked_model.load_state_dict(torch.load('clean_model.pth'))
    for param in attacked_model.feature_extractor.parameters():
        param.requires_grad = False

    optimizer_attacked = Adam(attacked_model.fc.parameters(), lr=1e-3)
    train_model(attacked_model, poisoned_loader, optimizer_attacked, criterion, n_epochs=15)

    torch.save(attacked_model.state_dict(), 'attacked_model.pth')


    acc = test_model(attacked_model, testloader)
    print(f'Clean accuracy on the attacked model is {acc:.2f}%')


    def predict_single(model, img):
        model.eval()
        with torch.no_grad():
            inp = img.unsqueeze(0).to(device)
            out = model(inp)
            return out.argmax(dim=1).item()

    print('Base image prediction:', predict_single(attacked_model, base_image))
    print('Target image prediction:', predict_single(attacked_model, target_image))
    print('Poison image prediction:', predict_single(attacked_model, poison))


    def feature_space_visualizaion(model, loader, poison_samples, base_class, target_class):
        model.eval()
        features = []
        labels = []

        with torch.no_grad():
            for inputs, targets in loader:
                inputs, targets = inputs.to(device), targets.to(device)
                f = model.get_features(inputs)
                features.append(f.cpu())
                labels.append(targets.cpu())

        features = torch.cat(features, dim=0)
        labels = torch.cat(labels, dim=0)

        if poison_samples is not None and len(poison_samples) > 0:
            with torch.no_grad():
                p_inputs = torch.stack(poison_samples).to(device)
                p_f = model.get_features(p_inputs)
            features = torch.cat([features, p_f.cpu()], dim=0)
            poison_labels = torch.tensor([999]*len(poison_samples))
            labels = torch.cat([labels, poison_labels], dim=0)

        mask = (labels == base_class) | (labels == target_class) | (labels == 999)
        features = features[mask]
        labels = labels[mask]

        tsne = TSNE(n_components=2, random_state=42)
        emb = tsne.fit_transform(features.numpy())

        plt.figure(figsize=(10,7))
        base_mask = (labels == base_class)
        target_mask = (labels == target_class)
        poison_mask = (labels == 999)

        plt.scatter(emb[base_mask,0], emb[base_mask,1], c='b', label='Base Class')
        plt.scatter(emb[target_mask,0], emb[target_mask,1], c='r', label='Target Class')
        if poison_mask.any():
            plt.scatter(emb[poison_mask,0], emb[poison_mask,1], c='g', marker='*', s=200, label='Poison')

        plt.legend()
        plt.title('Feature Space Visualization')
        plt.show()


    feature_space_visualizaion(clean_model, testloader, [poison], base_label, target_label)


    feature_space_visualizaion(attacked_model, testloader, [poison], base_label, target_label)


    def poisoning_watermark_generation(t, b, gamma=0.3):
        return gamma * t + (1 - gamma) * b


    base_class_indices = [i for i, (x,y) in enumerate(trainset) if y == base_label]
    poison_samples_wm = []
    poison_labels_wm = []

    for i in range(100):
        idx = base_class_indices[i]
        b_img, b_lbl = trainset[idx]
        wm_img = poisoning_watermark_generation(target_image, b_img, gamma=0.3)
        poison_samples_wm.append(wm_img)
        poison_labels_wm.append(target_label)

    for i in range(5):
        img = poison_samples_wm[i]
        plt.imshow(np.transpose((img * torch.tensor((0.2023, 0.1994, 0.2010)).view(3,1,1) + torch.tensor((0.4914, 0.4822, 0.4465)).view(3,1,1)).numpy(), (1,2,0)))
        plt.title(f'Watermark Poison Sample #{i}')
        plt.show()


    wm_dataset = TensorDataset(torch.stack(poison_samples_wm), torch.tensor(poison_labels_wm))
    watermark_dataset = ConcatDataset([trainset, wm_dataset])
    watermark_loader = DataLoader(watermark_dataset, batch_size=batch_size, shuffle=True, num_workers=2)

    print(f'The trainloader consists of {len(trainloader.dataset)} samples.')
    print(f'The poisoned trainloader consists of {len(poisoned_loader.dataset)} samples.')
    print(f'The watermark loader consists of {len(watermark_loader.dataset)} samples.')


    wm_model = ResNet18().to(device)
    wm_model.load_state_dict(torch.load('clean_model.pth'))
    for param in wm_model.feature_extractor.parameters():
        param.requires_grad = False

    optimizer_wm = Adam(wm_model.fc.parameters(), lr=1e-3)
    train_model(wm_model, watermark_loader, optimizer_wm, criterion, n_epochs=15)
    torch.save(wm_model.state_dict(), 'wm_model.pth')


    acc_wm = test_model(wm_model, testloader)
    print(f'Clean accuracy on the watermark model is {acc_wm:.2f}%')

    print('Base image prediction (wm model):', predict_single(wm_model, base_image))
    print('Target image prediction (wm model):', predict_single(wm_model, target_image))
    print('Poison image prediction (wm model):', predict_single(wm_model, poison))


    feature_space_visualizaion(wm_model, testloader, [poison], base_label, target_label)


if __name__ == "__main__":
    main()
