{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ooJtNr5dGrH9"
   },
   "source": [
    "**Name:** Fateme Raeijian\n",
    "\n",
    "**Student Number:** 402203389"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJm9Z1k0cdmh"
   },
   "source": [
    "# Neural-Network with Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDN075MYGesD"
   },
   "source": [
    "In this notebook, you are going to write and implement all the components required to create and train a two-layered neural network using NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wt3FdxgNcdmm"
   },
   "source": [
    "## Imports & Seeding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPZ4zlnxqhl5"
   },
   "source": [
    "Importing some common libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Et7OS7TGcdmn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "np.random.seed(42)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fa2v2-xbcdmo"
   },
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKWqV2Gycdmp"
   },
   "source": [
    "You'll train and evaluate your model on [Fashion MNIST](https://en.wikipedia.org/wiki/Fashion_MNIST) dataset. In this section, you'll download Fashion MNIST and split it into training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tMYZtSoLc7c-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784) (70000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Using `fetch_openml`, download `Fashion-MNIST` \n",
    "# and save the training data and labels in `X` and `y` respectively.\n",
    "#############################\n",
    "# Your code goes here (5 points)\n",
    "X, y = fetch_openml('Fashion-MNIST', version=1, return_X_y=True)\n",
    "#############################\n",
    "\n",
    "# Normalization:\n",
    "X = ((X / 255.) - .5) * 2\n",
    "\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sDmxyMJ4dBk3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,) (10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Using `train_test_split`, split your data into two sets. \n",
    "# Set the test_size to 10000\n",
    "\n",
    "#############################\n",
    "# Your code goes here (6 points)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=10000, random_state=42)\n",
    "#############################\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PiGTXGXKcdmt"
   },
   "source": [
    "## Prepare training & validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba3nNYlDcdmt"
   },
   "source": [
    "We'll use only 3 classes from Fashion MNIST: Trouser, T-shirt, and Sneaker classes.\n",
    "\n",
    "The class labels for T-shirt, Trouser, and Sneaker are 0, 1, and 7 respectively.\n",
    "\n",
    "In this part, you'll limit the testing and training sets to only these three classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TcBDZEtzcdmu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18022, 784) (18022,)\n"
     ]
    }
   ],
   "source": [
    "# Modify `y_train` and `x_train`.\n",
    "# Only keep the 3 classes mentioned above. \n",
    "#############################\n",
    "# Your code goes here (4 points)\n",
    "classes_to_keep = ['0', '1', '7']\n",
    "mask = np.isin(y_train, classes_to_keep)\n",
    "x_train = x_train[mask]\n",
    "y_train = y_train[mask]\n",
    "#############################\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LX2hkRe1cdmw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2978, 784) (2978,)\n"
     ]
    }
   ],
   "source": [
    "# Modify `y_test` and `x_test`.\n",
    "# Only keep the 3 classes mentioned above. \n",
    "#############################\n",
    "# Your code goes here (4 points)\n",
    "classes_to_keep = ['0', '1', '7']\n",
    "mask = np.isin(y_test, classes_to_keep)\n",
    "x_test = x_test[mask]\n",
    "y_test = y_test[mask]\n",
    "#############################\n",
    "\n",
    "print(x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gv6SMLUktWbv"
   },
   "source": [
    "## Linear & Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXlyJo5JteKC"
   },
   "source": [
    "In this part, you'll implement the forward and backward process for the following components:\n",
    "- Softmax Layer\n",
    "- Linear Layer\n",
    "- ReLU Layer\n",
    "- Sigmoid Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXtAD5uYA4sQ"
   },
   "source": [
    "### The `Softmax` Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftMaxLayer(object):\n",
    "    def __init__(self):\n",
    "        self.inp = None\n",
    "        self.output = None\n",
    "        self.inp_grad = None  # To store the gradient w.r.t input during backward pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Write the forward pass for softmax.\n",
    "        # Save the values required for the backward pass.\n",
    "        #############################\n",
    "        # Your code goes here (4 points)\n",
    "        x_stable = x - np.max(x, axis=1, keepdims=True)  # For numerical stability\n",
    "        exp_x = np.exp(x_stable)\n",
    "        sum_exp_x = np.sum(exp_x, axis=1, keepdims=True)\n",
    "        self.output = exp_x / sum_exp_x\n",
    "        self.inp = x  # Store input for backward pass\n",
    "        #############################\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, up_grad):\n",
    "        # Write the backward pass for softmax.\n",
    "        #############################\n",
    "        # Your code goes here (4 points)\n",
    "        s = self.output  # Softmax output from forward pass\n",
    "        # Compute dot product between up_grad and softmax output\n",
    "        tmp = np.sum(up_grad * s, axis=1, keepdims=True)\n",
    "        # Compute gradient w.r.t input\n",
    "        self.inp_grad = s * (up_grad - tmp)\n",
    "        #############################\n",
    "        return self.inp_grad  # Add this line to return the gradient\n",
    "\n",
    "    def step(self, optimizer):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcFoIDZjcdnB"
   },
   "source": [
    "### The `Linear` Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        # Initialize the layer's weights and biases\n",
    "        #############################\n",
    "        # Your code goes here (2 points)\n",
    "        self.w = np.random.randn(in_dim, out_dim) * np.sqrt(2. / in_dim)\n",
    "        self.b = np.zeros((1, out_dim))\n",
    "        #############################\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, inp):\n",
    "        # Compute linear layer's output.\n",
    "        # Save the value(s) required for the backward phase.\n",
    "        #############################\n",
    "        # Your code goes here (4 points)\n",
    "        self.inp = inp  # Save input for backward pass\n",
    "        z = np.dot(inp, self.w) + self.b\n",
    "        #############################\n",
    "\n",
    "        return z\n",
    "\n",
    "    def backward(self, up_grad):\n",
    "        # Calculate the gradient with respect to the weights \n",
    "        # and biases and save the results.\n",
    "        #############################\n",
    "        # Your code goes here (6 points)\n",
    "        self.dw = np.dot(self.inp.T, up_grad)\n",
    "        self.db = np.sum(up_grad, axis=0, keepdims=True)\n",
    "        down_grad = np.dot(up_grad, self.w.T)\n",
    "        #############################\n",
    "        return down_grad\n",
    "\n",
    "    def step(self, optimizer):\n",
    "        # Update the layer's weights and biases\n",
    "        # Update previous_w_update and previous_b_update accordingly\n",
    "        #############################\n",
    "        # Your code goes here (5 points)\n",
    "        self.w = optimizer.get_next_update(self.w, self.dw)\n",
    "        self.b = optimizer.get_next_update(self.b, self.db)\n",
    "        #############################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0Lfo-nhcdnG"
   },
   "source": [
    "### The `ReLU` Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "tN6vcirMcdnH"
   },
   "outputs": [],
   "source": [
    "class RelU:\n",
    "    def __init__(self):\n",
    "        self.inp = None\n",
    "\n",
    "    def forward(self, inp):\n",
    "        # Write the forward pass for ReLU.\n",
    "        # Save the value(s) required for the backward pass.\n",
    "        #############################\n",
    "        # Your code goes here (4 points)\n",
    "        self.inp = inp\n",
    "        output = np.maximum(0, inp)\n",
    "        #############################\n",
    "        return output\n",
    "\n",
    "    def backward(self, up_grad):\n",
    "        #############################\n",
    "        # Your code goes here (4 points)\n",
    "        down_grad = up_grad * (self.inp > 0).astype(up_grad.dtype)\n",
    "        #############################\n",
    "        return down_grad\n",
    "\n",
    "    def step(self, optimizer):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z00KoSI3cdnJ"
   },
   "source": [
    "### The `sigmoid` Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "TTYYeL2lcdnJ"
   },
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def forward(self, inp):\n",
    "        #############################\n",
    "        # Your code goes here (4 points)\n",
    "        self.out = 1 / (1 + np.exp(-inp))\n",
    "        #############################\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, up_grad):\n",
    "        #############################\n",
    "        # Your code goes here (4 points)\n",
    "        down_grad = up_grad * self.out * (1 - self.out)\n",
    "        #############################\n",
    "        return down_grad\n",
    "\n",
    "    def step(self, optimizer):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zngleGY2cdnK"
   },
   "source": [
    "## `Loss` function :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ISedT4FvcdnK"
   },
   "source": [
    "For this task we are going to use the [Cross-Entropy Loss](https://en.wikipedia.org/wiki/Cross_entropy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "XQyz4ybycdnL"
   },
   "outputs": [],
   "source": [
    "class CELoss():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        self.yhat = pred\n",
    "        self.y = target\n",
    "        m = self.y.shape[0]\n",
    "        # Compute and return the loss \n",
    "        #############################\n",
    "        # Your code goes here (8 points)\n",
    "        epsilon = 1e-15  # To prevent log(0)\n",
    "        loss = -np.sum(self.y * np.log(self.yhat + epsilon)) / m\n",
    "        #############################\n",
    "        return loss\n",
    "\n",
    "    def backward(self):\n",
    "        # Derivative of loss_fn with respect to the predicted label.\n",
    "        # Use `self.y` and `self.yhat` to compute and return `grad`.\n",
    "        #############################\n",
    "        # Your code goes here (6 points)\n",
    "        m = self.y.shape[0]\n",
    "        grad = (self.yhat - self.y) / m\n",
    "        #############################\n",
    "        return grad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xovZI-70kB9I"
   },
   "source": [
    "## Optimizer\n",
    "\n",
    "In this section, you'll implement an optimizer classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "h5ADTi5tkVTS"
   },
   "outputs": [],
   "source": [
    "class GradientDescent(object):\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "\n",
    "    def get_next_update(self, x, dx):\n",
    "        # Compute the new value for 'x' and return the result\n",
    "        #############################\n",
    "        # Your code goes here (2 points)\n",
    "        x_new = x - self.lr * dx\n",
    "        return x_new\n",
    "        #############################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxxrEEovYEFi"
   },
   "source": [
    "## The Model\n",
    "Now you'll write the base class for a multi-layer perceptron network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "t8SoZeYRcdnY"
   },
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, layers, loss_fn, optimizer):\n",
    "        self.layers = layers \n",
    "        self.losses  = [] \n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def forward(self, inp):\n",
    "        # Pass `inp` to all the layers sequentially\n",
    "        # and return the result.\n",
    "        #############################\n",
    "        # Your code goes here (4 points)\n",
    "        out = inp\n",
    "        for layer in self.layers:\n",
    "            out = layer.forward(out)\n",
    "        return out\n",
    "        #############################\n",
    "        \n",
    "    def loss(self, pred, label):\n",
    "        loss = self.loss_fn.forward(pred, label)\n",
    "        self.losses.append(loss)\n",
    "        return loss\n",
    "\n",
    "    def backward(self):\n",
    "        # Start with loss function's gradient and \n",
    "        # do the backward pass on all the layers.\n",
    "        #############################\n",
    "        # Your code goes here (5 points)\n",
    "        grad = self.loss_fn.backward()\n",
    "        for layer in reversed(self.layers):\n",
    "            grad = layer.backward(grad)\n",
    "        #############################\n",
    "        \n",
    "    def update(self):\n",
    "        for layer in self.layers:\n",
    "            layer.step(self.optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zo0rNwYciueF"
   },
   "source": [
    "The following cell encodes training labels into a one-hot representation with 3 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nhJTulaFJ4vR"
   },
   "outputs": [],
   "source": [
    "def onehot_enc(y, num_labels):\n",
    "    ary = np.zeros((y.shape[0], num_labels))\n",
    "    for i, val in enumerate(y):\n",
    "        ary[i, val] = 1\n",
    "    return ary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {'0': 0, '1': 1, '7': 2}\n",
    "\n",
    "y_train_mapped = np.array([label_mapping[val] for val in y_train])\n",
    "y_train = onehot_enc(y_train_mapped, 3)\n",
    "\n",
    "y_test_mapped = np.array([label_mapping[val] for val in y_test])\n",
    "y_test = onehot_enc(y_test_mapped, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "TS6S_RUwsRkF"
   },
   "outputs": [],
   "source": [
    "def train(model, epochs, x, y):\n",
    "    for n in range(epochs):\n",
    "        # First do the forward pass. Next, compute the loss.\n",
    "        # Then do the backward pass and finally, update the parameters.\n",
    "        #############################\n",
    "        # Your code goes here (4 points)\n",
    "        pred = model.forward(x)\n",
    "        loss = model.loss(pred, y)\n",
    "        model.backward()\n",
    "        model.update()\n",
    "        #############################\n",
    "        print(f\"Loss at {n}: {loss:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "m1lSq2jNcdnY",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at 0: 0.902\n",
      "Loss at 1: 0.820\n",
      "Loss at 2: 0.751\n",
      "Loss at 3: 0.695\n",
      "Loss at 4: 0.649\n",
      "Loss at 5: 0.610\n",
      "Loss at 6: 0.576\n",
      "Loss at 7: 0.547\n",
      "Loss at 8: 0.522\n",
      "Loss at 9: 0.499\n",
      "Loss at 10: 0.479\n",
      "Loss at 11: 0.461\n",
      "Loss at 12: 0.444\n",
      "Loss at 13: 0.429\n",
      "Loss at 14: 0.415\n",
      "Loss at 15: 0.402\n",
      "Loss at 16: 0.391\n",
      "Loss at 17: 0.380\n",
      "Loss at 18: 0.370\n",
      "Loss at 19: 0.361\n",
      "Loss at 20: 0.352\n",
      "Loss at 21: 0.344\n",
      "Loss at 22: 0.337\n",
      "Loss at 23: 0.330\n",
      "Loss at 24: 0.323\n",
      "Loss at 25: 0.317\n",
      "Loss at 26: 0.311\n",
      "Loss at 27: 0.305\n",
      "Loss at 28: 0.300\n",
      "Loss at 29: 0.295\n",
      "Loss at 30: 0.291\n",
      "Loss at 31: 0.286\n",
      "Loss at 32: 0.282\n",
      "Loss at 33: 0.278\n",
      "Loss at 34: 0.274\n",
      "Loss at 35: 0.271\n",
      "Loss at 36: 0.267\n",
      "Loss at 37: 0.264\n",
      "Loss at 38: 0.261\n",
      "Loss at 39: 0.258\n",
      "Loss at 40: 0.255\n",
      "Loss at 41: 0.252\n",
      "Loss at 42: 0.249\n",
      "Loss at 43: 0.246\n",
      "Loss at 44: 0.244\n",
      "Loss at 45: 0.241\n",
      "Loss at 46: 0.239\n",
      "Loss at 47: 0.237\n",
      "Loss at 48: 0.235\n",
      "Loss at 49: 0.232\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the `MLP` with the following structure:\n",
    "#     Linear with 50 units --> ReLU --> Linear with 50 units --> ReLU --> Linear with 3 units --> Sigmoid --> Softmax\n",
    "# Use GradientDescent as the optimizer, set the learning rate to 0.001, and use CELoss as the loss function.\n",
    "#############################\n",
    "# Your code goes here (4 points)\n",
    "layers = [\n",
    "    Linear(in_dim=x_train.shape[1], out_dim=50),\n",
    "    RelU(),\n",
    "    Linear(in_dim=50, out_dim=50),\n",
    "    RelU(),\n",
    "    Linear(in_dim=50, out_dim=3),\n",
    "    SoftMaxLayer()\n",
    "]\n",
    "\n",
    "\n",
    "optimizer = GradientDescent(lr=0.01)\n",
    "loss_fn = CELoss()\n",
    "nn = MLP(layers=layers, loss_fn=loss_fn, optimizer=optimizer)\n",
    "#############################\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "# Train the network using only `x_train` and `y_train` (no validation)\n",
    "train(nn, epochs, x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJec2xRJmY37"
   },
   "source": [
    "Let's plot the loss value for each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ymaQNn70cdnZ"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(nn.losses)\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dz3yqRa1cdna"
   },
   "source": [
    "**Let's also check our model's performance using the `accuracy` metric on the `testing` dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "TRqwXho7cdnd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 95.43%\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy on the testing set\n",
    "#############################\n",
    "# Your code goes here (7 points)\n",
    "predictions = nn.forward(x_test)\n",
    "\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "acc = np.mean(predicted_labels == true_labels)\n",
    "print(f\"Test Accuracy: {acc * 100:.2f}%\")\n",
    "\n",
    "#############################"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "spmlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
