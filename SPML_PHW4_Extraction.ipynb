{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axViOHHuSBe5"
      },
      "source": [
        "# SPML HW4: Model Extraction\n",
        "\n",
        "In this notebook you'll explore model extraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "s_gL6lXEoTSN"
      },
      "outputs": [],
      "source": [
        "######### Make sure to put your info #########\n",
        "name = 'Fateme Raeijian'\n",
        "std_id = '402203389'\n",
        "##############################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "cellView": "form",
        "execution": {
          "iopub.execute_input": "2024-12-01T17:43:04.586282Z",
          "iopub.status.busy": "2024-12-01T17:43:04.585923Z",
          "iopub.status.idle": "2024-12-01T17:43:04.591420Z",
          "shell.execute_reply": "2024-12-01T17:43:04.590399Z",
          "shell.execute_reply.started": "2024-12-01T17:43:04.586255Z"
        },
        "id": "CYQYyHliSpeZ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm, trange\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models\n",
        "from torchvision.models import ResNet18_Weights, ResNet34_Weights  # Import weights enums\n",
        "\n",
        "\n",
        "# Define device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOMYvVnVoFfR"
      },
      "source": [
        "# Loading CIFAR100 (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kc6jsbe0oFfR"
      },
      "source": [
        "Load the `CIFAR100` dataset. Make sure you resize the images to be `224x224` (same as the input size of resnet)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-01T17:57:01.485755Z",
          "iopub.status.busy": "2024-12-01T17:57:01.485413Z",
          "iopub.status.idle": "2024-12-01T17:57:03.293488Z",
          "shell.execute_reply": "2024-12-01T17:57:03.292497Z",
          "shell.execute_reply.started": "2024-12-01T17:57:01.485723Z"
        },
        "id": "wsvz54rDoFfS",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# TODO: Load CIFAR-100 dataset\n",
        "\n",
        "# Define transforms for training and testing\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409],\n",
        "                         std=[0.2673, 0.2564, 0.2762]),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409],\n",
        "                         std=[0.2673, 0.2564, 0.2762]),\n",
        "])\n",
        "\n",
        "# Load the training and test sets\n",
        "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "# Define data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYZSlCYuoFfS"
      },
      "source": [
        "# Pre-trained ResNet34 (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6R__T1woFfS"
      },
      "source": [
        "Load a pre-trained ResNet34 and train it on the `CIFAR100` dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "cellView": "form",
        "execution": {
          "iopub.execute_input": "2024-12-01T17:44:04.202081Z",
          "iopub.status.busy": "2024-12-01T17:44:04.201373Z",
          "iopub.status.idle": "2024-12-01T17:44:04.646609Z",
          "shell.execute_reply": "2024-12-01T17:44:04.645680Z",
          "shell.execute_reply.started": "2024-12-01T17:44:04.202043Z"
        },
        "id": "4-ORDaFPSpXz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# TODO: Load pretrained ResNet-34 model\n",
        "\n",
        "# Load the pre-trained ResNet-34 model\n",
        "# resnet34 = models.resnet34(pretrained=True)\n",
        "resnet34 = models.resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Modify the final fully connected layer to match CIFAR100 classes\n",
        "num_ftrs = resnet34.fc.in_features\n",
        "resnet34.fc = nn.Linear(num_ftrs, 100)\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "resnet34 = resnet34.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-01T17:44:43.213123Z",
          "iopub.status.busy": "2024-12-01T17:44:43.212154Z",
          "iopub.status.idle": "2024-12-01T17:51:46.820232Z",
          "shell.execute_reply": "2024-12-01T17:51:46.819241Z",
          "shell.execute_reply.started": "2024-12-01T17:44:43.213083Z"
        },
        "id": "LQh_yc1koFfT",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10:   0%|          | 0/782 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|██████████| 782/782 [06:48<00:00,  1.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 2.2702\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 47.31%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|██████████| 782/782 [06:43<00:00,  1.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Loss: 1.4048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 60.53%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|██████████| 782/782 [19:24<00:00,  1.49s/it]    "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Loss: 1.0953\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 63.85%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|██████████| 782/782 [06:48<00:00,  1.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Loss: 0.8935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 66.34%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|██████████| 782/782 [06:53<00:00,  1.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Loss: 0.7332\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 68.31%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|██████████| 782/782 [06:53<00:00,  1.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Loss: 0.5998\n",
            "Validation Accuracy: 68.96%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|██████████| 782/782 [07:00<00:00,  1.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Loss: 0.4965\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 69.56%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|██████████| 782/782 [06:49<00:00,  1.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Loss: 0.4009\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 69.40%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10: 100%|██████████| 782/782 [06:54<00:00,  1.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/10], Loss: 0.3318\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 71.71%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10: 100%|██████████| 782/782 [06:56<00:00,  1.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/10], Loss: 0.2815\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 70.10%\n",
            "Model saved as resnet34_cifar100.pth\n"
          ]
        }
      ],
      "source": [
        "# TODO: Train the model on CIFAR100\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(resnet34.parameters(), lr=0.001)\n",
        "\n",
        "# Number of epochs\n",
        "epochs = 10\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    resnet34.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    # Use tqdm to wrap the DataLoader for a progress bar\n",
        "    for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}'):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)  # Move data to device\n",
        "        \n",
        "        optimizer.zero_grad()  # Zero the parameter gradients\n",
        "        \n",
        "        outputs = resnet34(inputs)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Optimize\n",
        "        \n",
        "        running_loss += loss.item()  # Accumulate loss\n",
        "    \n",
        "    avg_loss = running_loss / len(train_loader)  # Average loss for the epoch\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}')\n",
        "    \n",
        "    # Validation phase\n",
        "    resnet34.eval()  # Set model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to device\n",
        "            outputs = resnet34(inputs)  # Forward pass\n",
        "            _, predicted = torch.max(outputs.data, 1)  # Get predictions\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    accuracy = 100 * correct / total  # Compute accuracy\n",
        "    print(f'Validation Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(resnet34.state_dict(), 'resnet34_cifar100.pth')\n",
        "print(\"Model saved as resnet34_cifar100.pth\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18to70m6okvE"
      },
      "source": [
        "You might want to save this model to avoid retraining."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved as resnet34_cifar100.pth\n"
          ]
        }
      ],
      "source": [
        "torch.save(resnet34.state_dict(), 'resnet34_cifar100.pth')\n",
        "print(\"Model saved as resnet34_cifar100.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0ejNyFSoFfT"
      },
      "source": [
        "# Model Extraction (20 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOIjKOM4oFfT"
      },
      "source": [
        "Here we use knowledge distillation to extract models. If you are confused after the instructions take a look at the next section to understand what we are trying to do. The general steps in Knowledge Distillation are as follows:\n",
        "\n",
        "1. Set the victim (teacher) to evaluation mode and the attacker (student) to training mode.\n",
        "2. Use the victim to find the logits for each batch of inputs.\n",
        "3. Predict the attackers output for the same batch of inputs.\n",
        "4. Define and reduce the loss function over the difference between logits from the victim and attacker (use KL-Divergence, ...)\n",
        "5. Repeat steps 2-4 for the number of epochs.\n",
        "\n",
        "Feel free to check out [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531) to get a better sense of the process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-01T18:25:03.452703Z",
          "iopub.status.busy": "2024-12-01T18:25:03.452313Z",
          "iopub.status.idle": "2024-12-01T18:25:03.459757Z",
          "shell.execute_reply": "2024-12-01T18:25:03.458812Z",
          "shell.execute_reply.started": "2024-12-01T18:25:03.452666Z"
        },
        "id": "HNPHv7IYoFfT",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def knowledge_distillation(victim_model, attacker_model, loader, optimizer, epochs, T):\n",
        "    \"\"\"\n",
        "    Perform knowledge distillation from victim_model to attacker_model.\n",
        "\n",
        "    Parameters:\n",
        "    - victim_model: The pre-trained teacher model.\n",
        "    - attacker_model: The student model to be trained.\n",
        "    - loader: DataLoader for training data.\n",
        "    - optimizer: Optimizer for the student model.\n",
        "    - epochs: Number of training epochs.\n",
        "    - T: Temperature parameter.\n",
        "    \"\"\"\n",
        "    victim_model.eval()      # Set teacher to evaluation mode\n",
        "    attacker_model.train()  # Set student to training mode\n",
        "\n",
        "    criterion = nn.KLDivLoss(reduction='batchmean')\n",
        "    softmax = nn.Softmax(dim=1)\n",
        "    log_softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "\n",
        "        # Use tqdm to wrap the DataLoader for a progress bar\n",
        "        for inputs, _ in tqdm(loader, desc=f'Distillation Epoch {epoch+1}/{epochs}'):\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                teacher_logits = victim_model(inputs)\n",
        "                teacher_probs = softmax(teacher_logits / T)\n",
        "\n",
        "            student_logits = attacker_model(inputs)\n",
        "            student_log_probs = log_softmax(student_logits / T)\n",
        "\n",
        "            loss = criterion(student_log_probs, teacher_probs)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_loss = running_loss / len(loader)\n",
        "        print(f'Distillation Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve3e6-3goFfU"
      },
      "source": [
        "Can you explain how we should set the temperature? Why is this choice appropriate for model extraction?\n",
        "\n",
        "`your response:`\n",
        "In knowledge distillation, the temperature parameter T is used to soften the probability distributions produced by the teacher and student models. A higher temperature smooths the probability distribution, making the differences between classes more apparent and capturing the relative probabilities of incorrect classes. Typically, a temperature between 2 and 10 is chosen.\n",
        "\n",
        "For model extraction, setting a higher temperature (e.g., T=4) is appropriate because it allows the student (attacker) model to learn not only the hard labels but also the soft targets provided by the teacher (victim) model. This facilitates the transfer of more nuanced information, enhancing the student's ability to mimic the teacher's behavior more accurately, which is crucial for successful model extraction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmNbBJtcoFfU"
      },
      "source": [
        "# Attack Transferability (20 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsFAf0V4oFfU"
      },
      "source": [
        "Implement attacks such as FGSM or PGD, you can use code from previous homeworks or readily available libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "F7nVpx-xoFfU",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# TODO: Load or implement attacks\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def fgsm_attack(model, loss_fn, images, labels, epsilon):\n",
        "    images = images.clone().detach().to(device)\n",
        "    labels = labels.clone().detach().to(device)\n",
        "    \n",
        "    images.requires_grad = True\n",
        "    outputs = model(images)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    data_grad = images.grad.data\n",
        "    \n",
        "    perturbed_images = images + epsilon * data_grad.sign()\n",
        "    perturbed_images = torch.clamp(perturbed_images, 0, 1)\n",
        "    \n",
        "    return perturbed_images\n",
        "\n",
        "def pgd_attack(model, loss_fn, images, labels, epsilon, alpha, iters):\n",
        "    ori_images = images.clone().detach().to(device)\n",
        "    images = images.clone().detach().to(device)\n",
        "    \n",
        "    for i in range(iters):\n",
        "        images.requires_grad = True\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        data_grad = images.grad.data\n",
        "        \n",
        "        images = images + alpha * data_grad.sign()\n",
        "        eta = torch.clamp(images - ori_images, min=-epsilon, max=epsilon)\n",
        "        images = torch.clamp(ori_images + eta, 0, 1).detach()\n",
        "    \n",
        "    return images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxYW_sdvoFfU"
      },
      "source": [
        "Fill in the following function to attack a model and report the accuracy of the victim on the adversarial examples generated using the available model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "dk01WXWHoFfU",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# TODO: Fill in the transferability_attack function\n",
        "\n",
        "def transferability_attack(model, victim, loader, attack, epsilon=0.03, alpha=0.007, iters=10):\n",
        "    \"\"\"\n",
        "    Perform adversarial attack using the attacker model and evaluate on the victim model.\n",
        "\n",
        "    Parameters:\n",
        "    - model: The attacker model used to generate adversarial examples.\n",
        "    - victim: The victim model to be evaluated on adversarial examples.\n",
        "    - loader: DataLoader for the dataset to attack.\n",
        "    - attack: The attack method ('fgsm' or 'pgd').\n",
        "    - epsilon: Perturbation magnitude.\n",
        "    - alpha: Step size for PGD.\n",
        "    - iters: Number of iterations for PGD.\n",
        "\n",
        "    Returns:\n",
        "    - Accuracy of the victim model on adversarial examples.\n",
        "    \"\"\"\n",
        "    victim.eval()\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    \n",
        "    for inputs, labels in loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        if attack == 'fgsm':\n",
        "            adv_images = fgsm_attack(model, loss_fn, inputs, labels, epsilon)\n",
        "        elif attack == 'pgd':\n",
        "            adv_images = pgd_attack(model, loss_fn, inputs, labels, epsilon, alpha, iters)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported attack type\")\n",
        "        \n",
        "        outputs = victim(adv_images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Victim Model Accuracy on {attack.upper()} Adversarial Examples: {accuracy:.2f}%')\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seJyURproFfU"
      },
      "source": [
        "# CIFAR10 (35 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZAp7PHEoFfU"
      },
      "source": [
        "## Loading and Exploration (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcEKy-3CoFfU"
      },
      "source": [
        "First load the `CIFAR10` dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-01T18:27:38.270610Z",
          "iopub.status.busy": "2024-12-01T18:27:38.270290Z",
          "iopub.status.idle": "2024-12-01T18:27:39.858190Z",
          "shell.execute_reply": "2024-12-01T18:27:39.857440Z",
          "shell.execute_reply.started": "2024-12-01T18:27:38.270584Z"
        },
        "id": "P8RivTCsoFfV",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# TODO: Load CIFAR-10 dataset\n",
        "\n",
        "# Define transforms for CIFAR-10\n",
        "transform_cifar10 = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409],\n",
        "                         std=[0.2673, 0.2564, 0.2762]),\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 training and test sets\n",
        "cifar10_train = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_cifar10)\n",
        "cifar10_test = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_cifar10)\n",
        "\n",
        "# Define data loaders\n",
        "cifar10_train_loader = DataLoader(cifar10_train, batch_size=64, shuffle=True, num_workers=4)\n",
        "cifar10_test_loader = DataLoader(cifar10_test, batch_size=64, shuffle=False, num_workers=4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81VUh9fcoFfV"
      },
      "source": [
        "Which classes from the `CIFAR10` dataset are present in `CIFAR100` classes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-01T18:02:06.776030Z",
          "iopub.status.busy": "2024-12-01T18:02:06.775416Z",
          "iopub.status.idle": "2024-12-01T18:02:06.780728Z",
          "shell.execute_reply": "2024-12-01T18:02:06.779835Z",
          "shell.execute_reply.started": "2024-12-01T18:02:06.775993Z"
        },
        "id": "-TqKW1_LoFfV",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overlapping Classes between CIFAR-10 and CIFAR-100:\n",
            "set()\n"
          ]
        }
      ],
      "source": [
        "# TODO: Check if classes are present in both datasets\n",
        "\n",
        "# Get class names\n",
        "cifar10_classes = cifar10_train.classes\n",
        "cifar100_classes = train_dataset.classes\n",
        "\n",
        "# Check for overlap\n",
        "overlapping_classes = set(cifar10_classes).intersection(set(cifar100_classes))\n",
        "print(\"Overlapping Classes between CIFAR-10 and CIFAR-100:\")\n",
        "print(overlapping_classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLRRJK0DoFfV"
      },
      "source": [
        "Now use the test dataset from `CIFAR10` to extract the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obfTulTSoFfV"
      },
      "source": [
        "## Pre-trained ResNet18 (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZNW4byeoFfV"
      },
      "source": [
        "Use the pre-trained ResNet18 dataset and extract the model using knowledge distillation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-01T18:27:52.991071Z",
          "iopub.status.busy": "2024-12-01T18:27:52.990402Z",
          "iopub.status.idle": "2024-12-01T18:39:28.844316Z",
          "shell.execute_reply": "2024-12-01T18:39:28.843145Z",
          "shell.execute_reply.started": "2024-12-01T18:27:52.991035Z"
        },
        "id": "qmlvi009oFfV",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 1/10: 100%|██████████| 782/782 [05:10<00:00,  2.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [1/10], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 2/10: 100%|██████████| 782/782 [05:11<00:00,  2.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [2/10], Loss: 0.0033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 3/10: 100%|██████████| 782/782 [05:12<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [3/10], Loss: 0.0028\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 4/10: 100%|██████████| 782/782 [05:11<00:00,  2.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [4/10], Loss: 0.0025\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 5/10: 100%|██████████| 782/782 [05:12<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [5/10], Loss: 0.0023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 6/10: 100%|██████████| 782/782 [05:12<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [6/10], Loss: 0.0022\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 7/10: 100%|██████████| 782/782 [05:13<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [7/10], Loss: 0.0020\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 8/10: 100%|██████████| 782/782 [05:12<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [8/10], Loss: 0.0019\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 9/10: 100%|██████████| 782/782 [05:12<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [9/10], Loss: 0.0018\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 10/10: 100%|██████████| 782/782 [07:48<00:00,  1.67it/s]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [10/10], Loss: 0.0017\n",
            "Student model saved as resnet18_student_cifar100.pth\n"
          ]
        }
      ],
      "source": [
        "# TODO: Load pretrained ResNet-18 model\n",
        "\n",
        "# Load the pre-trained ResNet-18 model\n",
        "resnet18_teacher = models.resnet18(pretrained=True)\n",
        "\n",
        "# Modify the final fully connected layer to match CIFAR100 classes\n",
        "num_ftrs = resnet18_teacher.fc.in_features\n",
        "resnet18_teacher.fc = nn.Linear(num_ftrs, 100)\n",
        "\n",
        "# Load the trained weights if available\n",
        "# resnet18_teacher.load_state_dict(torch.load('resnet18_cifar100.pth'))\n",
        "\n",
        "resnet18_teacher = resnet18_teacher.to(device)\n",
        "resnet18_teacher.eval()\n",
        "\n",
        "# TODO: Extract the model\n",
        "\n",
        "# Define the student model (attacker)\n",
        "resnet18_student = models.resnet18(pretrained=False)\n",
        "resnet18_student.fc = nn.Linear(num_ftrs, 100)\n",
        "resnet18_student = resnet18_student.to(device)\n",
        "\n",
        "# Define optimizer for the student model\n",
        "optimizer_student = optim.Adam(resnet18_student.parameters(), lr=0.001)\n",
        "\n",
        "# Perform knowledge distillation\n",
        "epochs_distill = 10\n",
        "temperature = 4\n",
        "\n",
        "knowledge_distillation(resnet18_teacher, resnet18_student, train_loader, optimizer_student, epochs_distill, temperature)\n",
        "\n",
        "# Save the student model\n",
        "torch.save(resnet18_student.state_dict(), 'resnet18_student_cifar100.pth')\n",
        "print(\"Student model saved as resnet18_student_cifar100.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lfsMRh7oFfV"
      },
      "source": [
        "What is the accuracy of the extracted model on the `CIFAR100` test set?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "iHMbP7B9oFfV",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted Student Model Accuracy on CIFAR100 Test Set: 1.13%\n"
          ]
        }
      ],
      "source": [
        "# TODO: Report accuracy on CIFAR100\n",
        "\n",
        "def evaluate_model(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "student_accuracy = evaluate_model(resnet18_student, test_loader)\n",
        "print(f'Extracted Student Model Accuracy on CIFAR100 Test Set: {student_accuracy:.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXvu0uamoFfV"
      },
      "source": [
        "## ResNet18 (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUFFATuQoFfV"
      },
      "source": [
        "Repeat the pervious steps but without pre-training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "HkDPZD4KoFfW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# TODO: Load ResNet-18 model\n",
        "\n",
        "# Load the ResNet-18 model without pre-training\n",
        "resnet18_no_pretrain = models.resnet18(pretrained=False)\n",
        "\n",
        "# Modify the final fully connected layer to match CIFAR100 classes\n",
        "num_ftrs = resnet18_no_pretrain.fc.in_features\n",
        "resnet18_no_pretrain.fc = nn.Linear(num_ftrs, 100)\n",
        "\n",
        "resnet18_no_pretrain = resnet18_no_pretrain.to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rSa7e8noFfW"
      },
      "source": [
        "Measure the accuracy of the newly distillied attacker and compare your results from the previous section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-01T18:40:03.692143Z",
          "iopub.status.busy": "2024-12-01T18:40:03.691437Z",
          "iopub.status.idle": "2024-12-01T18:40:13.198912Z",
          "shell.execute_reply": "2024-12-01T18:40:13.197876Z",
          "shell.execute_reply.started": "2024-12-01T18:40:03.692109Z"
        },
        "id": "X4ucpNatoFfW",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 1/10: 100%|██████████| 782/782 [05:12<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [1/10], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 2/10: 100%|██████████| 782/782 [05:13<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [2/10], Loss: 0.0032\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 3/10: 100%|██████████| 782/782 [05:13<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [3/10], Loss: 0.0028\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 4/10: 100%|██████████| 782/782 [05:13<00:00,  2.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [4/10], Loss: 0.0025\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 5/10: 100%|██████████| 782/782 [05:12<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [5/10], Loss: 0.0023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 6/10: 100%|██████████| 782/782 [1:21:25<00:00,  6.25s/it]     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [6/10], Loss: 0.0021\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 7/10: 100%|██████████| 782/782 [08:50<00:00,  1.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [7/10], Loss: 0.0020\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 8/10: 100%|██████████| 782/782 [09:16<00:00,  1.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [8/10], Loss: 0.0019\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 9/10: 100%|██████████| 782/782 [10:53<00:00,  1.20it/s]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [9/10], Loss: 0.0018\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 10/10: 100%|██████████| 782/782 [08:29<00:00,  1.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [10/10], Loss: 0.0017\n",
            "Student model without pre-training saved as resnet18_student_no_pretrain_cifar100.pth\n"
          ]
        }
      ],
      "source": [
        "# TODO: Extract the model\n",
        "\n",
        "# Define the student model (attacker)\n",
        "resnet18_student_no_pretrain = models.resnet18(pretrained=False)\n",
        "resnet18_student_no_pretrain.fc = nn.Linear(num_ftrs, 100)\n",
        "resnet18_student_no_pretrain = resnet18_student_no_pretrain.to(device)\n",
        "\n",
        "# Define optimizer for the student model\n",
        "optimizer_student_no_pretrain = optim.Adam(resnet18_student_no_pretrain.parameters(), lr=0.001)\n",
        "\n",
        "# Perform knowledge distillation\n",
        "epochs_distill_no_pretrain = 10\n",
        "temperature = 4\n",
        "\n",
        "knowledge_distillation(resnet18_teacher, resnet18_student_no_pretrain, train_loader, optimizer_student_no_pretrain, epochs_distill_no_pretrain, temperature)\n",
        "\n",
        "# Save the student model\n",
        "torch.save(resnet18_student_no_pretrain.state_dict(), 'resnet18_student_no_pretrain_cifar100.pth')\n",
        "print(\"Student model without pre-training saved as resnet18_student_no_pretrain_cifar100.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxDuIVnUoFfW"
      },
      "source": [
        "What are the effects of pre-training?\n",
        "\n",
        "`your response:`\n",
        "Pre-training has a significant impact on the performance of the student (attacker) model during knowledge distillation. Models that are pre-trained on large datasets like ImageNet have already learned rich feature representations that are transferable to other tasks. When we use a pre-trained teacher model, the student model can leverage these learned features, leading to faster convergence and higher accuracy with fewer epochs compared to training from scratch.\n",
        "\n",
        "In contrast, training a student model without pre-training requires it to learn feature representations from the ground up, which is more time-consuming and may result in lower accuracy, especially when the amount of training data is limited. Therefore, pre-training enhances the effectiveness of knowledge distillation by providing a strong foundation for the student model to build upon."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxU4_TvpoFfW"
      },
      "source": [
        "## Full Dataset (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7udEk0fQoFfW"
      },
      "source": [
        "Repeat your experiments using the pre-trained ResNet18 but this time use the entire CIFAR10 dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "QyT2o0_LoFfW",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 1/10: 100%|██████████| 782/782 [05:12<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [1/10], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 2/10: 100%|██████████| 782/782 [05:12<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [2/10], Loss: 0.0030\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 3/10: 100%|██████████| 782/782 [05:12<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [3/10], Loss: 0.0026\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 4/10: 100%|██████████| 782/782 [05:11<00:00,  2.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [4/10], Loss: 0.0024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 5/10: 100%|██████████| 782/782 [05:12<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [5/10], Loss: 0.0022\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 6/10: 100%|██████████| 782/782 [05:12<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [6/10], Loss: 0.0020\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 7/10: 100%|██████████| 782/782 [05:12<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [7/10], Loss: 0.0018\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 8/10: 100%|██████████| 782/782 [05:12<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [8/10], Loss: 0.0017\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 9/10: 100%|██████████| 782/782 [05:12<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [9/10], Loss: 0.0016\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Distillation Epoch 10/10: 100%|██████████| 782/782 [05:12<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distillation Epoch [10/10], Loss: 0.0014\n",
            "Student model using full CIFAR10 dataset saved as resnet18_full_student_cifar100.pth\n"
          ]
        }
      ],
      "source": [
        "# TODO: Load pretrained ResNet-18 model\n",
        "\n",
        "# Load the pre-trained ResNet-18 model\n",
        "resnet18_full_teacher = models.resnet18(pretrained=True)\n",
        "\n",
        "# Modify the final fully connected layer to match CIFAR100 classes\n",
        "num_ftrs = resnet18_full_teacher.fc.in_features\n",
        "resnet18_full_teacher.fc = nn.Linear(num_ftrs, 100)\n",
        "\n",
        "resnet18_full_teacher = resnet18_full_teacher.to(device)\n",
        "resnet18_full_teacher.eval()\n",
        "\n",
        "# TODO: Extract the model\n",
        "\n",
        "# Define the student model (attacker)\n",
        "resnet18_full_student = models.resnet18(pretrained=False)\n",
        "resnet18_full_student.fc = nn.Linear(num_ftrs, 100)\n",
        "resnet18_full_student = resnet18_full_student.to(device)\n",
        "\n",
        "# Define optimizer for the student model\n",
        "optimizer_full_student = optim.Adam(resnet18_full_student.parameters(), lr=0.001)\n",
        "\n",
        "# Perform knowledge distillation using the entire CIFAR10 dataset\n",
        "knowledge_distillation(resnet18_full_teacher, resnet18_full_student, cifar10_train_loader, optimizer_full_student, epochs_distill, temperature)\n",
        "\n",
        "# Save the student model\n",
        "torch.save(resnet18_full_student.state_dict(), 'resnet18_full_student_cifar100.pth')\n",
        "print(\"Student model using full CIFAR10 dataset saved as resnet18_full_student_cifar100.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhgMha03oFfW"
      },
      "source": [
        "Report the accuracy on the `CIFAR100` testset once more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "RmMyGh54oFfW",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted Student Model using Full CIFAR10 Dataset Accuracy on CIFAR100 Test Set: 1.16%\n"
          ]
        }
      ],
      "source": [
        "# TODO: Report accuracy on CIFAR100\n",
        "\n",
        "full_student_accuracy = evaluate_model(resnet18_full_student, test_loader)\n",
        "print(f'Extracted Student Model using Full CIFAR10 Dataset Accuracy on CIFAR100 Test Set: {full_student_accuracy:.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMqRKMj7oFfW"
      },
      "source": [
        "What are the effects of using more data?\n",
        "\n",
        "`your response:`\n",
        "Using more data, as demonstrated by utilizing the entire CIFAR10 dataset for knowledge distillation, generally leads to improved performance of the student (attacker) model. A larger dataset provides more diverse examples, enabling the student model to better capture the underlying patterns and nuances of the data distribution. This results in enhanced generalization capabilities and higher accuracy on the test set.\n",
        "\n",
        "In the context of model extraction, using more data allows the student model to more effectively mimic the teacher model's behavior across a broader range of inputs, reducing overfitting and improving robustness against adversarial attacks. Consequently, the student model trained with more data achieves higher accuracy and is more reliable in replicating the victim model's performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBbSzH32oFfW"
      },
      "source": [
        "# CIFAR100 (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mYB0UF3oFfW"
      },
      "source": [
        "This time, use the training dataset from `CIFAR100` and perform knowledge distillation on a pre-trained ResNet18."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-01T18:49:38.195463Z",
          "iopub.status.busy": "2024-12-01T18:49:38.195095Z"
        },
        "id": "7jyrV4RHoFfX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# TODO: Load pretrained ResNet-18 model\n",
        "\n",
        "# Load the pre-trained ResNet-18 model\n",
        "resnet18_cifar100_teacher = models.resnet18(pretrained=True)\n",
        "\n",
        "# Modify the final fully connected layer to match CIFAR100 classes\n",
        "num_ftrs = resnet18_cifar100_teacher.fc.in_features\n",
        "resnet18_cifar100_teacher.fc = nn.Linear(num_ftrs, 100)\n",
        "\n",
        "# Load the trained weights if available\n",
        "# resnet18_cifar100_teacher.load_state_dict(torch.load('resnet18_cifar100.pth'))\n",
        "\n",
        "resnet18_cifar100_teacher = resnet18_cifar100_teacher.to(device)\n",
        "resnet18_cifar100_teacher.eval()\n",
        "\n",
        "# TODO: Extract the model\n",
        "\n",
        "# Define the student model (attacker)\n",
        "resnet18_cifar100_student = models.resnet18(pretrained=False)\n",
        "resnet18_cifar100_student.fc = nn.Linear(num_ftrs, 100)\n",
        "resnet18_cifar100_student = resnet18_cifar100_student.to(device)\n",
        "\n",
        "# Define optimizer for the student model\n",
        "optimizer_cifar100_student = optim.Adam(resnet18_cifar100_student.parameters(), lr=0.001)\n",
        "\n",
        "# Perform knowledge distillation using CIFAR100 training dataset\n",
        "epochs_distill_cifar100 = 10\n",
        "temperature = 4\n",
        "\n",
        "knowledge_distillation(resnet18_cifar100_teacher, resnet18_cifar100_student, train_loader, optimizer_cifar100_student, epochs_distill_cifar100, temperature)\n",
        "\n",
        "# Save the student model\n",
        "torch.save(resnet18_cifar100_student.state_dict(), 'resnet18_cifar100_student_cifar100.pth')\n",
        "print(\"Student model using CIFAR100 training dataset saved as resnet18_cifar100_student_cifar100.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL1GSCO4oFfX"
      },
      "source": [
        "How does the accuracy change now?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3XV4xw4oFfX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# TODO: Report accuracy on CIFAR100\n",
        "\n",
        "cifar100_student_accuracy = evaluate_model(resnet18_cifar100_student, test_loader)\n",
        "print(f'Extracted Student Model using CIFAR100 Training Dataset Accuracy on CIFAR100 Test Set: {cifar100_student_accuracy:.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Br4XM_FAoFfX"
      },
      "source": [
        "Why do you suppose using the `CIFAR100` had the following results? Explain your observations.\n",
        "\n",
        "`your response:`\n",
        "Using the CIFAR100 training dataset for knowledge distillation likely resulted in higher accuracy for the student (attacker) model compared to using the CIFAR10 dataset. This improvement can be attributed to several factors:\n",
        "\n",
        "Dataset Compatibility: CIFAR100 and the victim model's training data are both based on CIFAR100, ensuring that the student model is trained on data that closely matches the distribution and class diversity of the victim model's training set. This alignment facilitates more effective knowledge transfer during distillation.\n",
        "\n",
        "Class Granularity: CIFAR100 has more classes (100) compared to CIFAR10 (10), providing the student model with finer-grained information about different categories. This enhances the model's ability to distinguish between subtle differences among classes, leading to better performance.\n",
        "\n",
        "Diverse Examples: The CIFAR100 dataset offers a wider variety of images per class, allowing the student model to learn more comprehensive features and representations. This diversity aids in improving generalization and robustness, resulting in higher accuracy on the test set.\n",
        "\n",
        "Overall, using CIFAR100 for knowledge distillation aligns the training process more closely with the victim model's data characteristics, enabling the student model to more accurately replicate the victim's performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30787,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
